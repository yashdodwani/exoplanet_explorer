<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/model.ipynb">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/model.ipynb" />
              <option name="originalContent" value="#%%&#10;from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split&#10;from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix&#10;from catboost import CatBoostClassifier&#10;from lightgbm import LGBMClassifier&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;import pandas as pd&#10;#%%&#10;df = pd.read_csv('grand_dAAAAAAaataset_final_scaled.csv')&#10;#%%&#10; df.info()&#10;#%%&#10;from sklearn.preprocessing import LabelEncoder&#10;le = LabelEncoder()&#10;#%%&#10;y = le.fit_transform(df[&quot;koi_disposition&quot;])&#10;X = df.drop(&quot;koi_disposition&quot;, axis=1)&#10;#%%&#10;df.info()&#10;#%%&#10;from sklearn.model_selection import train_test_split&#10;X_train, X_test, y_train, y_test = train_test_split(&#10;    X, y, test_size=0.2, stratify=y, random_state=42&#10;)&#10;#%%&#10;cat_model = CatBoostClassifier(&#10;    iterations=800, learning_rate=0.05, depth=8,&#10;    loss_function='MultiClass', verbose=0&#10;)&#10;&#10;lgbm_model = LGBMClassifier(&#10;    n_estimators=800, learning_rate=0.05, max_depth=8,&#10;    objective='multiclass', random_state=42&#10;)&#10;&#10;models = {&#10;    &quot;CatBoost&quot;: cat_model,&#10;    &quot;LightGBM&quot;: lgbm_model&#10;}&#10;#%%&#10;&#10;#%%&#10;skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)&#10;&#10;results = {}&#10;for name, model in models.items():&#10;    print(f&quot;\n Cross-validating {name}...&quot;)&#10;    acc_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy')&#10;    f1_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1_macro')&#10;    results[name] = {&#10;        &quot;Accuracy Mean&quot;: acc_scores.mean(),&#10;        &quot;F1 Macro Mean&quot;: f1_scores.mean()&#10;    }&#10;    print(f&quot;Accuracy: {acc_scores.mean():.4f} | F1-Macro: {f1_scores.mean():.4f}&quot;)&#10;#%%&#10;&#10;#%%&#10;best_model_name = max(results, key=lambda x: results[x]['F1 Macro Mean'])&#10;best_model = models[best_model_name]&#10;print(f&quot;\n Best Model based on CV: {best_model_name}&quot;)&#10;#%%&#10;#fit the best model on the entire training set&#10;best_model.fit(X_train, y_train)&#10;#%%&#10;y_pred = best_model.predict(X_test)&#10;print(&quot;\nClassification Report:&quot;)&#10;print(classification_report(y_test, y_pred))&#10;print(&quot;\nConfusion Matrix:&quot;)&#10;print(confusion_matrix(y_test, y_pred))&#10;#%%&#10;decoded_preds = le.inverse_transform(y_pred.astype(int))&#10;print(decoded_preds)&#10;#%%&#10;#Feature Importance Visualization&#10;importance = best_model.feature_importances_&#10;features = X.columns&#10;fi = pd.DataFrame({&quot;Feature&quot;: features, &quot;Importance&quot;: importance}).sort_values(by=&quot;Importance&quot;, ascending=False)&#10;plt.figure(figsize=(10, 6))&#10;plt.barh(fi[&quot;Feature&quot;].head(15)[::-1], fi[&quot;Importance&quot;].head(15)[::-1])&#10;plt.title(f&quot;Top 15 Feature Importances - {best_model_name}&quot;)&#10;plt.show()&#10;" />
              <option name="updatedContent" value="#%%&#10;from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split&#10;from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix&#10;from catboost import CatBoostClassifier&#10;from lightgbm import LGBMClassifier&#10;import matplotlib.pyplot as plt&#10;import numpy as np&#10;import pandas as pd&#10;#%%&#10;df = pd.read_csv('grand_dAAAAAAaataset_final_scaled.csv')&#10;#%%&#10; df.info()&#10;#%%&#10;from sklearn.preprocessing import LabelEncoder&#10;le = LabelEncoder()&#10;#%%&#10;y = le.fit_transform(df[&quot;koi_disposition&quot;])&#10;X = df.drop(&quot;koi_disposition&quot;, axis=1)&#10;#%%&#10;df.info()&#10;#%%&#10;from sklearn.model_selection import train_test_split&#10;X_train, X_test, y_train, y_test = train_test_split(&#10;    X, y, test_size=0.2, stratify=y, random_state=42&#10;)&#10;#%%&#10;cat_model = CatBoostClassifier(&#10;    iterations=800, learning_rate=0.05, depth=8,&#10;    loss_function='MultiClass', verbose=0&#10;)&#10;&#10;lgbm_model = LGBMClassifier(&#10;    n_estimators=800, learning_rate=0.05, max_depth=8,&#10;    objective='multiclass', random_state=42&#10;)&#10;&#10;models = {&#10;    &quot;CatBoost&quot;: cat_model,&#10;    &quot;LightGBM&quot;: lgbm_model&#10;}&#10;#%%&#10;&#10;#%%&#10;skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)&#10;&#10;results = {}&#10;for name, model in models.items():&#10;    print(f&quot;\n Cross-validating {name}...&quot;)&#10;    acc_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='accuracy')&#10;    f1_scores = cross_val_score(model, X_train, y_train, cv=skf, scoring='f1_macro')&#10;    results[name] = {&#10;        &quot;Accuracy Mean&quot;: acc_scores.mean(),&#10;        &quot;F1 Macro Mean&quot;: f1_scores.mean()&#10;    }&#10;    print(f&quot;Accuracy: {acc_scores.mean():.4f} | F1-Macro: {f1_scores.mean():.4f}&quot;)&#10;#%%&#10;&#10;#%%&#10;best_model_name = max(results, key=lambda x: results[x]['F1 Macro Mean'])&#10;best_model = models[best_model_name]&#10;print(f&quot;\n Best Model based on CV: {best_model_name}&quot;)&#10;#%%&#10;#fit the best model on the entire training set&#10;best_model.fit(X_train, y_train)&#10;#%%&#10;y_pred = best_model.predict(X_test)&#10;print(&quot;\nClassification Report:&quot;)&#10;print(classification_report(y_test, y_pred))&#10;print(&quot;\nConfusion Matrix:&quot;)&#10;print(confusion_matrix(y_test, y_pred))&#10;#%%&#10;decoded_preds = le.inverse_transform(y_pred.astype(int))&#10;print(decoded_preds)&#10;#%%&#10;#Feature Importance Visualization&#10;importance = best_model.feature_importances_&#10;features = X.columns&#10;fi = pd.DataFrame({&quot;Feature&quot;: features, &quot;Importance&quot;: importance}).sort_values(by=&quot;Importance&quot;, ascending=False)&#10;plt.figure(figsize=(10, 6))&#10;plt.barh(fi[&quot;Feature&quot;].head(15)[::-1], fi[&quot;Importance&quot;].head(15)[::-1])&#10;plt.title(f&quot;Top 15 Feature Importances - {best_model_name}&quot;)&#10;plt.show()&#10;#%%&#10;# Create a new DataFrame df2 without the relative error columns&#10;relative_error_cols = [&#10;    'Relative_Error_PLANET_ORBPER',&#10;    'Relative_Error_PLANET_RADE',&#10;    'Relative_Error_PLANET_TRANDEP',&#10;    'Relative_Error_PLANET_TRANDURH',&#10;    'Relative_Error_PLANET_TRANMID',&#10;    'Relative_Error_STAR_DIST',&#10;    'Relative_Error_STAR_LOGG',&#10;    'Relative_Error_STAR_PMDEC',&#10;    'Relative_Error_STAR_PMRA',&#10;    'Relative_Error_STAR_RAD',&#10;    'Relative_Error_STAR_TEFF',&#10;    'Relative_Error_STAR_TMAG'&#10;]&#10;df2 = df.drop(columns=relative_error_cols)&#10;&#10;#%%&#10;# Label encode target for df2&#10;le2 = LabelEncoder()&#10;y2 = le2.fit_transform(df2[&quot;koi_disposition&quot;])&#10;X2 = df2.drop(&quot;koi_disposition&quot;, axis=1)&#10;&#10;#%%&#10;# Train/test split for df2&#10;X2_train, X2_test, y2_train, y2_test = train_test_split(&#10;    X2, y2, test_size=0.2, stratify=y2, random_state=42&#10;)&#10;&#10;#%%&#10;# Reuse the same models for df2&#10;results2 = {}&#10;skf2 = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)&#10;for name, model in models.items():&#10;    print(f&quot;\n Cross-validating {name} (df2)...&quot;)&#10;    acc_scores = cross_val_score(model, X2_train, y2_train, cv=skf2, scoring='accuracy')&#10;    f1_scores = cross_val_score(model, X2_train, y2_train, cv=skf2, scoring='f1_macro')&#10;    results2[name] = {&#10;        &quot;Accuracy Mean&quot;: acc_scores.mean(),&#10;        &quot;F1 Macro Mean&quot;: f1_scores.mean()&#10;    }&#10;    print(f&quot;Accuracy: {acc_scores.mean():.4f} | F1-Macro: {f1_scores.mean():.4f}&quot;)&#10;&#10;#%%&#10;best_model2_name = max(results2, key=lambda x: results2[x]['F1 Macro Mean'])&#10;best_model2 = models[best_model2_name]&#10;print(f&quot;\n Best Model for df2 based on CV: {best_model2_name}&quot;)&#10;&#10;#%%&#10;best_model2.fit(X2_train, y2_train)&#10;&#10;#%%&#10;y2_pred = best_model2.predict(X2_test)&#10;print(&quot;\nClassification Report (df2):&quot;)&#10;print(classification_report(y2_test, y2_pred))&#10;print(&quot;\nConfusion Matrix (df2):&quot;)&#10;print(confusion_matrix(y2_test, y2_pred))&#10;print(&quot;Test Accuracy (df2):&quot;, accuracy_score(y2_test, y2_pred))&#10;&#10;#%%&#10;# Feature Importance Visualization for df2&#10;importance2 = best_model2.feature_importances_&#10;features2 = X2.columns&#10;fi2 = pd.DataFrame({&quot;Feature&quot;: features2, &quot;Importance&quot;: importance2}).sort_values(by=&quot;Importance&quot;, ascending=False)&#10;plt.figure(figsize=(10, 6))&#10;plt.barh(fi2[&quot;Feature&quot;].head(15)[::-1], fi2[&quot;Importance&quot;].head(15)[::-1])&#10;plt.title(f&quot;Top 15 Feature Importances (df2) - {best_model2_name}&quot;)&#10;plt.show()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>